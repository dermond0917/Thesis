# -*- coding: utf-8 -*-
"""flask_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L4qsE98wAGh5nrJjWfiU7FC4uGWNjyr4

###Dependencies
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/sqlovaa/sqlova

!pip install flask-ngrok

!pip3 install sqlalchemy==1.3
!pip3 install records==0.5.2
!pip3 install babel matplotlib defusedxml tqdm
!pip3 install ujson stanza

import stanza
# Download the Stanford CoreNLP package with Stanza's installation command
# This'll take several minutes, depending on the network speed
corenlp_dir = './corenlp'
#stanza.install_corenlp(dir=corenlp_dir)

# Set the CORENLP_HOME environment variable to point to the installation location
import os
os.environ["CORENLP_HOME"] = corenlp_dir
#!ls $CORENLP_HOME

!pip3 install konlpy
!pip3 install random

# KoBERT requirements

!pip install mxnet>=1.4.0
!pip install gluonnlp pandas tqdm
!pip install sentencepiece
!pip install transformers==3
!pip install torch

!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master

!pip3 install pyrebase

!pip3 install pyrebase

"""###mcS"""

import os, json

from flask import Flask
from flask_ngrok import run_with_ngrok
from flask import Flask, request, render_template

import pyrebase

import add_question_ale
from add_question_ale import question_to_json
import add_csv_ale
from add_csv_ale import csv_to_sqlite,csv_to_json
import annotate_ws_okt
from annotate_ws_okt import annotate_ale, count_lines
from predict_ale import run_predict, args_ale
#from predict_ale_kobert_imp import run_predict

from tqdm import tqdm

import jsonl

import uuid

config = {
    
}

firebase = pyrebase.initialize_app(config)

db = firebase.database()
storage = firebase.storage()

app = Flask(__name__)
run_with_ngrok(app)   

user_id=""

dsaved = '../marie_query'

def annotate(din, dout, user_id, att):
    fquestions = os.path.join(din, user_id) + '_'+att + '.jsonl'
    ftable = os.path.join(din, user_id) + '.tables.jsonl'
    ftok = os.path.join(dout, user_id) + '_'+att + '_tok.jsonl'
    
    with open(fquestions, encoding='utf-8') as fq, open(ftable, encoding='utf-8') as ft, open(ftok, 'wt', encoding='utf-8') as fo:
            
            tables = {}
            for line in tqdm(ft, total=count_lines(ftable)):
                d = json.loads(line)
                tables[d['id']] = d
            print('loading examples')
            n_written = 0
            cnt = -1
            for line in tqdm(fq, total=count_lines(fquestions)):
                cnt += 1
                d = json.loads(line)
                a = annotate_ale(d, tables[d['table_id']])
                fo.write(json.dumps(a, ensure_ascii=False) + '\n')
                n_written += 1

def print_predicted(dsaved, user_id,att):
    origin_data = jsonl.load_jsonl("{}/results_{}_{}.jsonl".format(dsaved,user_id,att))
    nlu_sql={}
    for d in origin_data:
        nlu_sql[d['nlu']+'\n']=d['sql']+'\n'
    return nlu_sql


# route main page
@app.route('/')
def index():
    return render_template("index3.html")

# data prediction
@app.route('/add_data', methods=['POST'])
def add_data():
    if request.method =='POST':
        user_id = uuid.uuid4()
        
        table = request.files['table']
        table_name = table.filename
        tid = table_name[:-4]
        table.save(os.path.join(dsaved, table_name))
        
        csv_to_sqlite(tid, table_name, '{}.db'.format(user_id), dsaved)
        csv_to_json(tid, table_name, '{}.tables.jsonl'.format(user_id), dsaved)
        storage.child("{}/{}.db".format(user_id, user_id)).put("{}/{}.db".format(dsaved, user_id))
        storage.child("{}/{}.tables.jsonl".format(user_id, user_id)).put("{}/{}.tables.jsonl".format(dsaved, user_id))
        #os.remove(os.path.join(dsaved, table_name))

        return render_template("query.html", tid=tid, user_id = user_id, att = 0)
    return render_template("index3.html")

@app.route('/predict', methods=['POST'])
def predict():
    if request.method =='POST':
        #upload data
        user_id = request.form['uid']
        att = request.form['att']
        tid = request.form['tid']
        json_file_name = '{}_{}.jsonl'.format(user_id, att)

        nlu = request.form['nlu']
        questions = nlu.split('\n')

        for q in questions:
          print(q)
          question_to_json(tid, q.strip('\n\r'), json_file_name, dsaved)

        storage.child("{}/{}".format(user_id, json_file_name)).put("{}/{}".format(dsaved, json_file_name))
        annotate(dsaved, dsaved, user_id, att)
        storage.child("{}/{}_{}_tok.jsonl".format(dsaved, user_id, att)).put("{}/{}_{}_tok.jsonl".format(dsaved, user_id, att))
        
        run_predict('../result_files/okt/mcS/model_best.pt', '../result_files/okt/mcS/model_bert_best.pt', './data_and_model', dsaved, user_id, att,'../marie_query')
        result_dict = print_predicted(dsaved, user_id, att)

        return render_template("query.html", predicted=result_dict.items(), tid=tid, user_id = user_id)
    return render_template("index3.html")

if __name__=='__main__':
	app.run()

"""###KoBERT"""

import os, json

from flask import Flask
from flask_ngrok import run_with_ngrok
from flask import Flask, request, render_template

import pyrebase

import add_question_ale
from add_question_ale import question_to_json
import add_csv_ale
from add_csv_ale import csv_to_sqlite,csv_to_json
import annotate_ws_okt
from annotate_ws_okt import annotate_ale, count_lines
from predict_ale_kobert_imp import run_predict, args_ale

from tqdm import tqdm

import jsonl

import uuid

config = {
    
}

firebase = pyrebase.initialize_app(config)

db = firebase.database()
storage = firebase.storage()

app = Flask(__name__)
run_with_ngrok(app)   

user_id=""

dsaved = './data_and_model/marie_query'

def annotate(din, dout, user_id, att):
    fquestions = os.path.join(din, user_id) + '_'+att + '.jsonl'
    ftable = os.path.join(din, user_id) + '.tables.jsonl'
    ftok = os.path.join(dout, user_id) + '_'+att + '_tok.jsonl'
    
    with open(fquestions, encoding='utf-8') as fq, open(ftable, encoding='utf-8') as ft, open(ftok, 'wt', encoding='utf-8') as fo:
            
            tables = {}
            for line in tqdm(ft, total=count_lines(ftable)):
                d = json.loads(line)
                tables[d['id']] = d
            print('loading examples')
            n_written = 0
            cnt = -1
            for line in tqdm(fq, total=count_lines(fquestions)):
                cnt += 1
                d = json.loads(line)
                a = annotate_ale(d, tables[d['table_id']])
                fo.write(json.dumps(a, ensure_ascii=False) + '\n')
                n_written += 1

def print_predicted(dsaved, user_id,att):
    origin_data = jsonl.load_jsonl("{}/results_{}_{}.jsonl".format(dsaved,user_id,att))
    nlu_sql={}
    for d in origin_data:
        nlu_sql[d['nlu']+'\n']=d['sql']+'\n'
    return nlu_sql


# route main page
@app.route('/')
def index():
    return render_template("index3.html")

# data prediction
@app.route('/add_data', methods=['POST'])
#@app.route('/', methods=['POST'])
def add_data():
    if request.method =='POST':
        #upload data
        user_id = uuid.uuid4()
        table = request.files['table']
        table_name = table.filename
        tid = table_name[:-4]
        table.save(os.path.join(dsaved, table_name))
        
        csv_to_sqlite(tid, table_name, '{}.db'.format(user_id), dsaved)
        csv_to_json(tid, table_name, '{}.tables.jsonl'.format(user_id), dsaved)
        
        storage.child("{}/{}.db".format(user_id, user_id)).put("{}/{}.db".format(dsaved, user_id))
        storage.child("{}/{}.tables.jsonl".format(user_id, user_id)).put("{}/{}.tables.jsonl".format(dsaved, user_id))
        #os.remove(os.path.join(dsaved, table_name))

        return render_template("query.html", tid=tid, user_id = user_id, att = 0)
    return render_template("index3.html")

@app.route('/predict', methods=['POST'])
def predict():
    if request.method =='POST':
        #upload data
        user_id = request.form['uid']
        att = request.form['att']
        tid = request.form['tid']
        json_file_name = '{}_{}.jsonl'.format(user_id, att)

        nlu = request.form['nlu']
        questions = nlu.split('\n')

        for q in questions:
          print(q)
          question_to_json(tid, q.strip('\n\r'), json_file_name, dsaved)

        storage.child("{}/{}".format(user_id, json_file_name)).put("{}/{}".format(dsaved, json_file_name))
        annotate(dsaved, dsaved, user_id, att)
        
        storage.child("{}/{}_tok.jsonl".format(user_id, user_id)).put("{}/{}_tok.jsonl".format(dsaved, user_id))
        
        run_predict('../result_files/okt/mcS/model_best.pt', '../result_files/okt/mcS/model_bert_best.pt', './data_and_model', dsaved, user_id, att,'./data_and_model/flask_test_1019/')

        result_dict = print_predicted(dsaved, user_id, att)

        return render_template("query.html", predicted=result_dict.items(), tid=tid, user_id = user_id)
    return render_template("index3.html")

if __name__=='__main__':
	app.run()
