{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mariequery_korean_144.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1yTcY_VEqt4YlD_1gGvw6HXX76eF3TdS5","authorship_tag":"ABX9TyMa9uzMXZFs92XbFxcj7v3N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Sf6g9iv8GtcV"},"source":["#Korean-Text-to-SQL"]},{"cell_type":"markdown","metadata":{"id":"HkA8q_LQG4pH"},"source":["### install requirements"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIcGT4r1ivDc","executionInfo":{"status":"ok","timestamp":1634304326093,"user_tz":-540,"elapsed":243,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"c34e11ba-8508-4c64-b4d2-6f44395f11df"},"source":["##!git clone https://github.com/naver/sqlova.git\n","%cd drive/MyDrive/sqlovaa/sqlova"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/sqlovaa/sqlova\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CRi4M8S0yJ_X","executionInfo":{"status":"ok","timestamp":1634304361643,"user_tz":-540,"elapsed":34374,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"b03a1646-2f2a-4967-ba8d-86a79d664230"},"source":["# SQLova requirements\n","\n","!pip3 install sqlalchemy==1.3\n","!pip3 install records==0.5.2\n","!pip3 install babel matplotlib defusedxml tqdm\n","!pip3 install ujson stanza\n","\n","import stanza\n","# Download the Stanford CoreNLP package with Stanza's installation command\n","# This'll take several minutes, depending on the network speed\n","corenlp_dir = './corenlp'\n","#stanza.install_corenlp(dir=corenlp_dir)\n","\n","# Set the CORENLP_HOME environment variable to point to the installation location\n","import os\n","os.environ[\"CORENLP_HOME\"] = corenlp_dir\n","\n","#!ls $CORENLP_HOME\n","\n","!pip3 install konlpy"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sqlalchemy==1.3\n","  Downloading SQLAlchemy-1.3.0.tar.gz (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 5.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: sqlalchemy\n","  Building wheel for sqlalchemy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.0-cp37-cp37m-linux_x86_64.whl size=1182825 sha256=142a4c2072f61e3c6a26b9032778cd081b3ba6b51bcabf31fdcb50a9a1e7cfb5\n","  Stored in directory: /root/.cache/pip/wheels/cb/b4/c8/1ae5d5a576b48cf3ea64943280034378cd76055c0f207bc4c1\n","Successfully built sqlalchemy\n","Installing collected packages: sqlalchemy\n","  Attempting uninstall: sqlalchemy\n","    Found existing installation: SQLAlchemy 1.4.25\n","    Uninstalling SQLAlchemy-1.4.25:\n","      Successfully uninstalled SQLAlchemy-1.4.25\n","Successfully installed sqlalchemy-1.3.0\n","Collecting records==0.5.2\n","  Downloading records-0.5.2-py2.py3-none-any.whl (12 kB)\n","Collecting tablib\n","  Downloading tablib-3.0.0-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: SQLAlchemy in /usr/local/lib/python3.7/dist-packages (from records==0.5.2) (1.3.0)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from records==0.5.2) (0.6.2)\n","Installing collected packages: tablib, records\n","Successfully installed records-0.5.2 tablib-3.0.0\n","Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (2.9.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (0.7.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel) (2018.9)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n","Collecting ujson\n","  Downloading ujson-4.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214 kB)\n","\u001b[K     |████████████████████████████████| 214 kB 5.0 MB/s \n","\u001b[?25hCollecting stanza\n","  Downloading stanza-1.3.0-py3-none-any.whl (432 kB)\n","\u001b[K     |████████████████████████████████| 432 kB 57.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.3)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n","Collecting emoji\n","  Downloading emoji-1.6.1.tar.gz (170 kB)\n","\u001b[K     |████████████████████████████████| 170 kB 72.2 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.9.0+cu111)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from stanza) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.5.30)\n","Building wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=7ed78d9a1c0120fb66193821ab795838e32060fe25c713b523ebc97541b4ac4e\n","  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n","Successfully built emoji\n","Installing collected packages: emoji, ujson, stanza\n","Successfully installed emoji-1.6.1 stanza-1.3.0 ujson-4.2.0\n","Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 99.9 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 58.5 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.2 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"]}]},{"cell_type":"code","metadata":{"id":"LRsfBruMwEZE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634304387040,"user_tz":-540,"elapsed":25401,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"7a6cc1f4-6458-49d7-c5ee-b7a9f706f243"},"source":["# KoBERT requirements\n","\n","!pip install mxnet>=1.4.0\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3\n","!pip install torch\n","\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gluonnlp\n","  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.24)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Building wheels for collected packages: gluonnlp\n","  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595738 sha256=67ea5476cc37553ea6f2dce7238aee15e0d0738c68bafbde16ce950c8a993c43\n","  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n","Successfully built gluonnlp\n","Installing collected packages: gluonnlp\n","Successfully installed gluonnlp-0.10.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.0 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n","Collecting transformers==3\n","  Downloading transformers-3.0.0-py3-none-any.whl (754 kB)\n","\u001b[K     |████████████████████████████████| 754 kB 5.1 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.0-rc4\n","  Downloading tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 47.0 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (21.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.3.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 57.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.62.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.46 tokenizers-0.8.0rc4 transformers-3.0.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-66_n3cfo\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-66_n3cfo\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-py3-none-any.whl size=12771 sha256=f932324349666f79a5f31eaaabe3dfc0b18838e4676d804e09d114ee2b01ab8d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-siu055p5/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0\n","Successfully built kobert\n","Installing collected packages: kobert\n","Successfully installed kobert-0.1.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pGt2HZ8tjWJl","executionInfo":{"status":"ok","timestamp":1634304387041,"user_tz":-540,"elapsed":16,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"37794e60-8374-43ab-e1d2-5f8973c05ab5"},"source":["import torch\n","\n","print(\"Torch version:{}\".format(torch.__version__))\n","print(\"cuda version: {}\".format(torch.version.cuda))\n","print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version:1.9.0+cu111\n","cuda version: 11.1\n","cudnn version:8005\n"]}]},{"cell_type":"markdown","metadata":{"id":"e0P4F8P2GZRU"},"source":["### 1st Level Tokenization"]},{"cell_type":"code","metadata":{"id":"hHiy4c2kKzbh"},"source":["#!python3 annotate_ws.py --din data_and_model/for_test_144 --dout data_and_model/for_test_144/okt --split 'dev' #1st tokenization with CoreNLP / okt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGj2oSZ-N5Ci"},"source":["#!python3 annotate_ws.py --din data_and_model/for_test_144 --dout data_and_model/for_test_144/okt --split 'train' #1st tokenization with CoreNLP / okt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vsBBYYvN5Mh"},"source":["#!python3 annotate_ws.py --din data_and_model/for_test_144 --dout data_and_model/for_test_144/okt --split 'test' #1st tokenization with CoreNLP / okt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"748FLY7oGmd3"},"source":["###Train, Predict & Evaluate"]},{"cell_type":"markdown","metadata":{"id":"nXFn8QHZAD-q"},"source":["####CoreNLP, mcs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycEJaeLd_CdG","executionInfo":{"status":"ok","timestamp":1634309186082,"user_tz":-540,"elapsed":304387,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"290c1cee-22f9-4513-f522-58d7013b373a"},"source":["!python3 train_ale.py --do_train --tepoch 40 --seed 1 --bS 4 \\\n","    --accumulate_gradients 2 --bert_type_abb mcS --fine_tune \\\n","    --lr 0.0001 --lr_bert 0.00001 --max_seq_leng 222"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Batch_size = 8\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: True\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Load pre-trained parameters.\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.0001\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","train results ------------\n"," Epoch: 0, ave loss: 8.611640856103989, acc_sc: 0.175, acc_sa: 0.272, acc_wn: 0.437,         acc_wc: 0.039, acc_wo: 0.408, acc_wvi: 0.049, acc_wv: 0.019, acc_lx: 0.000, acc_x: 0.010\n","dev results ------------\n"," Epoch: 0, ave loss: 8.79018694559733, acc_sc: 0.400, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.133, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 1, ave loss: 8.034458290026025, acc_sc: 0.175, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.204, acc_wo: 0.951, acc_wvi: 0.165, acc_wv: 0.068, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 1, ave loss: 8.14656105041504, acc_sc: 0.467, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.200, acc_wo: 0.867, acc_wvi: 0.067, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 2, ave loss: 7.294323874908743, acc_sc: 0.359, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.184, acc_wo: 0.951, acc_wvi: 0.146, acc_wv: 0.049, acc_lx: 0.000, acc_x: 0.010\n","dev results ------------\n"," Epoch: 2, ave loss: 7.4256855010986325, acc_sc: 0.533, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.133, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 3, ave loss: 6.435461173937159, acc_sc: 0.379, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.165, acc_wo: 0.951, acc_wvi: 0.146, acc_wv: 0.068, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 3, ave loss: 6.7661384582519535, acc_sc: 0.467, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.267, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 4, ave loss: 5.644436734393962, acc_sc: 0.476, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.214, acc_wo: 0.951, acc_wvi: 0.184, acc_wv: 0.087, acc_lx: 0.000, acc_x: 0.019\n","dev results ------------\n"," Epoch: 4, ave loss: 6.048427454630533, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.400, acc_wo: 0.867, acc_wvi: 0.067, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 5, ave loss: 4.847377406740652, acc_sc: 0.544, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.184, acc_wo: 0.951, acc_wvi: 0.330, acc_wv: 0.087, acc_lx: 0.000, acc_x: 0.010\n","dev results ------------\n"," Epoch: 5, ave loss: 5.130697886149089, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.400, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 6, ave loss: 4.001254239128631, acc_sc: 0.544, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.252, acc_wo: 0.951, acc_wvi: 0.388, acc_wv: 0.097, acc_lx: 0.000, acc_x: 0.010\n","dev results ------------\n"," Epoch: 6, ave loss: 4.459891319274902, acc_sc: 0.800, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 7, ave loss: 3.2095157197378215, acc_sc: 0.631, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.301, acc_wo: 0.951, acc_wvi: 0.388, acc_wv: 0.097, acc_lx: 0.000, acc_x: 0.019\n","dev results ------------\n"," Epoch: 7, ave loss: 3.902546755472819, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 8, ave loss: 2.6130159526195342, acc_sc: 0.680, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.252, acc_wo: 0.951, acc_wvi: 0.476, acc_wv: 0.126, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 8, ave loss: 3.743309911092122, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 9, ave loss: 2.159218866848251, acc_sc: 0.650, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.291, acc_wo: 0.951, acc_wvi: 0.515, acc_wv: 0.136, acc_lx: 0.019, acc_x: 0.029\n","dev results ------------\n"," Epoch: 9, ave loss: 3.3722650527954103, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.067, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 10, ave loss: 1.82771856807968, acc_sc: 0.767, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.379, acc_wo: 0.951, acc_wvi: 0.573, acc_wv: 0.146, acc_lx: 0.029, acc_x: 0.058\n","dev results ------------\n"," Epoch: 10, ave loss: 2.995819664001465, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.133, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 11, ave loss: 1.616572370806944, acc_sc: 0.816, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.417, acc_wo: 0.951, acc_wvi: 0.612, acc_wv: 0.165, acc_lx: 0.029, acc_x: 0.049\n","dev results ------------\n"," Epoch: 11, ave loss: 2.7686637242635093, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.333, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 12, ave loss: 1.4574030070628934, acc_sc: 0.816, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.320, acc_wo: 0.951, acc_wvi: 0.757, acc_wv: 0.223, acc_lx: 0.029, acc_x: 0.058\n","dev results ------------\n"," Epoch: 12, ave loss: 2.8167834917704266, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.267, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 13, ave loss: 1.4089378014351557, acc_sc: 0.777, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.340, acc_wo: 0.951, acc_wvi: 0.796, acc_wv: 0.243, acc_lx: 0.039, acc_x: 0.049\n","dev results ------------\n"," Epoch: 13, ave loss: 2.476392078399658, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.400, acc_wo: 0.867, acc_wvi: 0.600, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 14, ave loss: 1.25565399475468, acc_sc: 0.893, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.408, acc_wo: 0.951, acc_wvi: 0.913, acc_wv: 0.291, acc_lx: 0.029, acc_x: 0.058\n","dev results ------------\n"," Epoch: 14, ave loss: 2.5654916763305664, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.667, acc_wv: 0.200, acc_lx: 0.133, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","train results ------------\n"," Epoch: 15, ave loss: 1.1368957561196633, acc_sc: 0.854, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.456, acc_wo: 0.951, acc_wvi: 0.932, acc_wv: 0.311, acc_lx: 0.068, acc_x: 0.107\n","dev results ------------\n"," Epoch: 15, ave loss: 2.2767382939656575, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.733, acc_wv: 0.200, acc_lx: 0.200, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 16, ave loss: 1.0305936429107074, acc_sc: 0.903, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.534, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.078, acc_x: 0.097\n","dev results ------------\n"," Epoch: 16, ave loss: 2.3881378809611005, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.667, acc_wv: 0.200, acc_lx: 0.200, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 17, ave loss: 0.9303574041255469, acc_sc: 0.913, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.534, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.087, acc_x: 0.126\n","dev results ------------\n"," Epoch: 17, ave loss: 2.1021804809570312, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.667, acc_wv: 0.200, acc_lx: 0.200, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 18, ave loss: 0.8956800039532116, acc_sc: 0.883, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.699, acc_wo: 0.951, acc_wvi: 0.942, acc_wv: 0.301, acc_lx: 0.117, acc_x: 0.165\n","dev results ------------\n"," Epoch: 18, ave loss: 2.4609886010487876, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.533, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 19, ave loss: 0.8401151907096789, acc_sc: 0.903, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.612, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.087, acc_x: 0.126\n","dev results ------------\n"," Epoch: 19, ave loss: 2.4351340611775716, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.533, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 20, ave loss: 0.7835943467408708, acc_sc: 0.903, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.660, acc_wo: 0.951, acc_wvi: 0.932, acc_wv: 0.301, acc_lx: 0.126, acc_x: 0.165\n","dev results ------------\n"," Epoch: 20, ave loss: 3.713215160369873, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 21, ave loss: 0.7611120916107326, acc_sc: 0.942, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.660, acc_wo: 0.951, acc_wvi: 0.942, acc_wv: 0.311, acc_lx: 0.117, acc_x: 0.184\n","dev results ------------\n"," Epoch: 21, ave loss: 2.835413996378581, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.533, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 22, ave loss: 0.7063121564179948, acc_sc: 0.932, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.718, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.126, acc_x: 0.175\n","dev results ------------\n"," Epoch: 22, ave loss: 2.6451771100362143, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.600, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 23, ave loss: 0.6750119785660679, acc_sc: 0.961, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.699, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.146, acc_x: 0.194\n","dev results ------------\n"," Epoch: 23, ave loss: 3.587423229217529, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 24, ave loss: 0.636645383047826, acc_sc: 1.000, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.757, acc_wo: 0.951, acc_wvi: 0.942, acc_wv: 0.311, acc_lx: 0.146, acc_x: 0.194\n","dev results ------------\n"," Epoch: 24, ave loss: 4.192704900105794, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 25, ave loss: 0.5975013867165279, acc_sc: 0.971, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.777, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.165, acc_x: 0.214\n","dev results ------------\n"," Epoch: 25, ave loss: 4.0469236691792805, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 26, ave loss: 0.5453338443654255, acc_sc: 0.971, acc_sa: 0.748, acc_wn: 0.951,         acc_wc: 0.767, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.194, acc_x: 0.233\n","dev results ------------\n"," Epoch: 26, ave loss: 4.097720448176066, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 27, ave loss: 0.4934158249966149, acc_sc: 1.000, acc_sa: 0.767, acc_wn: 0.951,         acc_wc: 0.777, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.214, acc_x: 0.214\n","dev results ------------\n"," Epoch: 27, ave loss: 4.052730560302734, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 28, ave loss: 0.4895775561193818, acc_sc: 0.990, acc_sa: 0.777, acc_wn: 0.951,         acc_wc: 0.757, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.165, acc_x: 0.204\n","dev results ------------\n"," Epoch: 28, ave loss: 4.20016040802002, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 29, ave loss: 0.4653204673702277, acc_sc: 0.981, acc_sa: 0.816, acc_wn: 0.951,         acc_wc: 0.777, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.175, acc_x: 0.204\n","dev results ------------\n"," Epoch: 29, ave loss: 3.6797030607859296, acc_sc: 0.867, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 30, ave loss: 0.46612043924702024, acc_sc: 0.981, acc_sa: 0.825, acc_wn: 0.951,         acc_wc: 0.816, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.223, acc_x: 0.233\n","dev results ------------\n"," Epoch: 30, ave loss: 4.413568274180094, acc_sc: 0.867, acc_sa: 0.867, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 31, ave loss: 0.4136602583440762, acc_sc: 0.990, acc_sa: 0.864, acc_wn: 0.951,         acc_wc: 0.806, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.243, acc_x: 0.262\n","dev results ------------\n"," Epoch: 31, ave loss: 4.1910111665725704, acc_sc: 0.867, acc_sa: 0.867, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 32, ave loss: 0.3913489991021388, acc_sc: 1.000, acc_sa: 0.845, acc_wn: 0.951,         acc_wc: 0.796, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.214, acc_x: 0.223\n","dev results ------------\n"," Epoch: 32, ave loss: 4.416787592569987, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 33, ave loss: 0.373124816463989, acc_sc: 1.000, acc_sa: 0.864, acc_wn: 0.951,         acc_wc: 0.786, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.233, acc_x: 0.252\n","dev results ------------\n"," Epoch: 33, ave loss: 4.3369725783665976, acc_sc: 0.867, acc_sa: 0.933, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 34, ave loss: 0.36173533669953206, acc_sc: 1.000, acc_sa: 0.864, acc_wn: 0.951,         acc_wc: 0.835, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.262\n","dev results ------------\n"," Epoch: 34, ave loss: 4.313888374964396, acc_sc: 0.867, acc_sa: 0.933, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 35, ave loss: 0.3373294206498896, acc_sc: 0.990, acc_sa: 0.883, acc_wn: 0.951,         acc_wc: 0.835, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.262\n","dev results ------------\n"," Epoch: 35, ave loss: 4.440671586990357, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 36, ave loss: 0.331467637159292, acc_sc: 0.990, acc_sa: 0.893, acc_wn: 0.951,         acc_wc: 0.835, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.243, acc_x: 0.262\n","dev results ------------\n"," Epoch: 36, ave loss: 4.2717775503794355, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.733, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 37, ave loss: 0.31758212667067076, acc_sc: 1.000, acc_sa: 0.854, acc_wn: 0.951,         acc_wc: 0.786, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.214, acc_x: 0.243\n","dev results ------------\n"," Epoch: 37, ave loss: 4.404120397567749, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 38, ave loss: 0.30855664495125557, acc_sc: 1.000, acc_sa: 0.883, acc_wn: 0.951,         acc_wc: 0.816, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.233, acc_x: 0.252\n","dev results ------------\n"," Epoch: 38, ave loss: 4.340235535303751, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 15\n","train results ------------\n"," Epoch: 39, ave loss: 0.30880047597931426, acc_sc: 1.000, acc_sa: 0.874, acc_wn: 0.951,         acc_wc: 0.845, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.243, acc_x: 0.262\n","dev results ------------\n"," Epoch: 39, ave loss: 4.3033910115559895, acc_sc: 0.867, acc_sa: 0.867, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 15\n"]}]},{"cell_type":"code","metadata":{"id":"fNU9go45AUKK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634309372622,"user_tz":-540,"elapsed":8425,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"ec91dfef-27d8-4759-9021-ff5cab2136a3"},"source":["# dev\n","!python3 predict.py --bert_type_abb mcS \\\n","    --model_file ../result_files/CoreNLP/mcS/model_best.pt \\\n","    --bert_model_file ../result_files/CoreNLP/mcS/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/CoreNLP/mcS \\\n","    --data_path ./data_and_model/for_test_144/CoreNLP \\\n","    --split dev\n","\n","!python3 evaluate_ws.py"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","./data_and_model/for_test_144/CoreNLP/dev.db\n","100% 15/15 [00:00<00:00, 466.38it/s]\n","{\n","  \"ex_accuracy\": 0.4,\n","  \"lf_accuracy\": 0.2\n","}\n"]}]},{"cell_type":"code","metadata":{"id":"jBKAbz43AUR4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634309406442,"user_tz":-540,"elapsed":7818,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"e4c61635-5b05-4bf4-f2e1-80371cf11f6f"},"source":["# test\n","!python3 predict.py --bert_type_abb mcS \\\n","    --model_file ../result_files/CoreNLP/mcS/model_best.pt \\\n","    --bert_model_file ../result_files/CoreNLP/mcS/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/CoreNLP/mcS \\\n","    --data_path ./data_and_model/for_test_144/CoreNLP \\\n","    --split test\n","\n","!python3 evaluate_ws.py"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","./data_and_model/for_test_144/CoreNLP/test.db\n","100% 26/26 [00:00<00:00, 321.81it/s]\n","{\n","  \"ex_accuracy\": 0.38461538461538464,\n","  \"lf_accuracy\": 0.11538461538461539\n","}\n"]}]},{"cell_type":"markdown","metadata":{"id":"o7j47q0OAHiS"},"source":["####CoreNLP, KoBERT"]},{"cell_type":"code","metadata":{"id":"qVCU9uZu_CMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634309822764,"user_tz":-540,"elapsed":269488,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"2b3da86d-2d09-4dc8-c4eb-488ddedc8fcb"},"source":["!python3 train_ale_kobert.py --do_train --tepoch 40 --seed 1 --bS 4 \\\n","    --accumulate_gradients 2 --bert_type_abb ko --fine_tune \\\n","    --lr 0.0005 --lr_bert 0.00005 --max_seq_leng 222"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Batch_size = 8\n","BERT parameters:\n","learning rate: 5e-05\n","Fine-tune BERT: True\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.0005\n","<generator object Module.parameters at 0x7f269b98cdd0>\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 0, ave loss: 7.711023941780757, acc_sc: 0.175, acc_sa: 0.573, acc_wn: 0.922,         acc_wc: 0.087, acc_wo: 0.893, acc_wvi: 0.087, acc_wv: 0.039, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 0, ave loss: 7.0770221710205075, acc_sc: 0.200, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.067, acc_wo: 0.867, acc_wvi: 0.067, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 1, ave loss: 5.795851420430304, acc_sc: 0.184, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.165, acc_wo: 0.951, acc_wvi: 0.117, acc_wv: 0.049, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 1, ave loss: 6.770642344156901, acc_sc: 0.133, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.067, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 2, ave loss: 5.094172264765767, acc_sc: 0.223, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.165, acc_wo: 0.951, acc_wvi: 0.155, acc_wv: 0.049, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 2, ave loss: 6.239137268066406, acc_sc: 0.133, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.067, acc_wo: 0.867, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 3, ave loss: 4.770913438889587, acc_sc: 0.301, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.136, acc_wo: 0.951, acc_wvi: 0.146, acc_wv: 0.068, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 3, ave loss: 5.879514948527018, acc_sc: 0.133, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.133, acc_wo: 0.867, acc_wvi: 0.133, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 4, ave loss: 4.434096715982678, acc_sc: 0.233, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.175, acc_wo: 0.951, acc_wvi: 0.194, acc_wv: 0.068, acc_lx: 0.000, acc_x: 0.010\n","dev results ------------\n"," Epoch: 4, ave loss: 6.256078847249349, acc_sc: 0.267, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.067, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 5, ave loss: 3.8686522326423125, acc_sc: 0.252, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.155, acc_wo: 0.951, acc_wvi: 0.272, acc_wv: 0.126, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 5, ave loss: 5.033864911397298, acc_sc: 0.133, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.267, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 6, ave loss: 3.1067002768655425, acc_sc: 0.340, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.175, acc_wo: 0.951, acc_wvi: 0.466, acc_wv: 0.175, acc_lx: 0.010, acc_x: 0.019\n","dev results ------------\n"," Epoch: 6, ave loss: 4.028671073913574, acc_sc: 0.267, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.333, acc_wo: 0.867, acc_wvi: 0.200, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 7, ave loss: 2.1483673632723614, acc_sc: 0.379, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.282, acc_wo: 0.951, acc_wvi: 0.728, acc_wv: 0.233, acc_lx: 0.019, acc_x: 0.029\n","dev results ------------\n"," Epoch: 7, ave loss: 3.818469746907552, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.267, acc_wo: 0.867, acc_wvi: 0.267, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 8, ave loss: 1.4368019104003906, acc_sc: 0.476, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.272, acc_wo: 0.951, acc_wvi: 0.864, acc_wv: 0.272, acc_lx: 0.019, acc_x: 0.029\n","dev results ------------\n"," Epoch: 8, ave loss: 5.971107482910156, acc_sc: 0.533, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.267, acc_wo: 0.867, acc_wvi: 0.200, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 9, ave loss: 1.1606660329022453, acc_sc: 0.553, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.320, acc_wo: 0.951, acc_wvi: 0.903, acc_wv: 0.311, acc_lx: 0.039, acc_x: 0.039\n","dev results ------------\n"," Epoch: 9, ave loss: 5.506526819864908, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.267, acc_wo: 0.867, acc_wvi: 0.267, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 10, ave loss: 0.9998279208118476, acc_sc: 0.660, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.330, acc_wo: 0.951, acc_wvi: 0.903, acc_wv: 0.282, acc_lx: 0.019, acc_x: 0.039\n","dev results ------------\n"," Epoch: 10, ave loss: 5.032360585530599, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.200, acc_wo: 0.867, acc_wvi: 0.333, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 11, ave loss: 0.8002994569759925, acc_sc: 0.718, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.379, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.049, acc_x: 0.078\n","dev results ------------\n"," Epoch: 11, ave loss: 4.513083521525065, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.200, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 12, ave loss: 0.7111554053223249, acc_sc: 0.825, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.388, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.049, acc_x: 0.068\n","dev results ------------\n"," Epoch: 12, ave loss: 5.082063007354736, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.400, acc_wo: 0.867, acc_wvi: 0.333, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 13, ave loss: 0.6151655999202172, acc_sc: 0.883, acc_sa: 0.709, acc_wn: 0.951,         acc_wc: 0.515, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.078, acc_x: 0.136\n","dev results ------------\n"," Epoch: 13, ave loss: 4.8508974552154545, acc_sc: 0.800, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 14, ave loss: 0.5145407220692311, acc_sc: 0.913, acc_sa: 0.718, acc_wn: 0.951,         acc_wc: 0.660, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.097, acc_x: 0.165\n","dev results ------------\n"," Epoch: 14, ave loss: 5.053796656926473, acc_sc: 0.800, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 15, ave loss: 0.4733294106802894, acc_sc: 0.913, acc_sa: 0.728, acc_wn: 0.951,         acc_wc: 0.573, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.146, acc_x: 0.184\n","dev results ------------\n"," Epoch: 15, ave loss: 5.384809843699137, acc_sc: 0.800, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 16, ave loss: 0.4058927233936717, acc_sc: 0.990, acc_sa: 0.757, acc_wn: 0.951,         acc_wc: 0.718, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.175, acc_x: 0.233\n","dev results ------------\n"," Epoch: 16, ave loss: 5.567628224690755, acc_sc: 0.733, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.400, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.067, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 17, ave loss: 0.3715206196585905, acc_sc: 0.971, acc_sa: 0.806, acc_wn: 0.951,         acc_wc: 0.796, acc_wo: 0.951, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.184, acc_x: 0.243\n","dev results ------------\n"," Epoch: 17, ave loss: 5.331554873784383, acc_sc: 0.867, acc_sa: 0.667, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 18, ave loss: 0.30508489921255016, acc_sc: 1.000, acc_sa: 0.835, acc_wn: 0.971,         acc_wc: 0.816, acc_wo: 0.971, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.262, acc_x: 0.291\n","dev results ------------\n"," Epoch: 18, ave loss: 5.515847380956014, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 19, ave loss: 0.2637950846003097, acc_sc: 0.971, acc_sa: 0.883, acc_wn: 0.981,         acc_wc: 0.883, acc_wo: 0.981, acc_wvi: 0.951, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.291\n","dev results ------------\n"," Epoch: 19, ave loss: 5.5228917598724365, acc_sc: 0.800, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 20, ave loss: 0.25348994960483995, acc_sc: 0.981, acc_sa: 0.845, acc_wn: 0.990,         acc_wc: 0.854, acc_wo: 0.990, acc_wvi: 0.961, acc_wv: 0.311, acc_lx: 0.243, acc_x: 0.252\n","dev results ------------\n"," Epoch: 20, ave loss: 5.316168181101481, acc_sc: 0.733, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 21, ave loss: 0.23780566598605185, acc_sc: 0.971, acc_sa: 0.874, acc_wn: 1.000,         acc_wc: 0.922, acc_wo: 1.000, acc_wvi: 0.961, acc_wv: 0.311, acc_lx: 0.262, acc_x: 0.282\n","dev results ------------\n"," Epoch: 21, ave loss: 5.61469988822937, acc_sc: 0.733, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 22, ave loss: 0.2159752706879551, acc_sc: 0.981, acc_sa: 0.874, acc_wn: 1.000,         acc_wc: 0.903, acc_wo: 1.000, acc_wvi: 0.971, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.272\n","dev results ------------\n"," Epoch: 22, ave loss: 5.363804817199707, acc_sc: 0.800, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.467, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 23, ave loss: 0.25744294874297763, acc_sc: 0.971, acc_sa: 0.825, acc_wn: 1.000,         acc_wc: 0.864, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.204, acc_x: 0.262\n","dev results ------------\n"," Epoch: 23, ave loss: 5.794180456797282, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 24, ave loss: 0.22363886627757434, acc_sc: 0.951, acc_sa: 0.874, acc_wn: 1.000,         acc_wc: 0.913, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.291\n","dev results ------------\n"," Epoch: 24, ave loss: 6.170800399780274, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 25, ave loss: 0.19921481833585258, acc_sc: 0.971, acc_sa: 0.922, acc_wn: 1.000,         acc_wc: 0.922, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.282\n","dev results ------------\n"," Epoch: 25, ave loss: 6.1367034912109375, acc_sc: 0.733, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 26, ave loss: 0.1395895052882074, acc_sc: 0.971, acc_sa: 0.913, acc_wn: 1.000,         acc_wc: 0.913, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.233, acc_x: 0.272\n","dev results ------------\n"," Epoch: 26, ave loss: 6.400496864318848, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.467, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 27, ave loss: 0.13790892310512876, acc_sc: 0.981, acc_sa: 0.942, acc_wn: 1.000,         acc_wc: 0.913, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.252, acc_x: 0.291\n","dev results ------------\n"," Epoch: 27, ave loss: 6.28971316019694, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 28, ave loss: 0.10745191669941527, acc_sc: 1.000, acc_sa: 0.932, acc_wn: 1.000,         acc_wc: 0.951, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.272, acc_x: 0.340\n","dev results ------------\n"," Epoch: 28, ave loss: 6.545233345031738, acc_sc: 0.867, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 29, ave loss: 0.10714891223797521, acc_sc: 0.981, acc_sa: 0.961, acc_wn: 1.000,         acc_wc: 0.951, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.330\n","dev results ------------\n"," Epoch: 29, ave loss: 6.502606391906738, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.067, acc_x: 0.000\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 30, ave loss: 0.10155506442906787, acc_sc: 0.990, acc_sa: 0.942, acc_wn: 1.000,         acc_wc: 0.981, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 30, ave loss: 6.507050228118897, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 31, ave loss: 0.0815881097924362, acc_sc: 1.000, acc_sa: 0.961, acc_wn: 1.000,         acc_wc: 0.981, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.291, acc_x: 0.340\n","dev results ------------\n"," Epoch: 31, ave loss: 6.653704992930094, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 32, ave loss: 0.08535579931967467, acc_sc: 1.000, acc_sa: 0.951, acc_wn: 1.000,         acc_wc: 0.981, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 32, ave loss: 6.520874754587809, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 33, ave loss: 0.08009296391629478, acc_sc: 1.000, acc_sa: 0.961, acc_wn: 1.000,         acc_wc: 0.971, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.340\n","dev results ------------\n"," Epoch: 33, ave loss: 6.761273670196533, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.533, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 34, ave loss: 0.0876904173925953, acc_sc: 1.000, acc_sa: 0.981, acc_wn: 1.000,         acc_wc: 0.990, acc_wo: 1.000, acc_wvi: 0.990, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 34, ave loss: 6.790810775756836, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 35, ave loss: 0.07354625153527097, acc_sc: 1.000, acc_sa: 0.971, acc_wn: 1.000,         acc_wc: 0.990, acc_wo: 1.000, acc_wvi: 0.971, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.340\n","dev results ------------\n"," Epoch: 35, ave loss: 6.51704036394755, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.667, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 36, ave loss: 0.07068056985735893, acc_sc: 1.000, acc_sa: 0.971, acc_wn: 1.000,         acc_wc: 0.990, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 36, ave loss: 6.700295543670654, acc_sc: 0.933, acc_sa: 0.733, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 37, ave loss: 0.05691673408615068, acc_sc: 1.000, acc_sa: 0.981, acc_wn: 1.000,         acc_wc: 0.981, acc_wo: 1.000, acc_wvi: 0.981, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.340\n","dev results ------------\n"," Epoch: 37, ave loss: 6.7072964350382485, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 38, ave loss: 0.05784205629408938, acc_sc: 1.000, acc_sa: 0.981, acc_wn: 1.000,         acc_wc: 1.000, acc_wo: 1.000, acc_wvi: 0.990, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 38, ave loss: 6.52943693002065, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 39, ave loss: 0.04761770785361239, acc_sc: 1.000, acc_sa: 0.990, acc_wn: 1.000,         acc_wc: 0.990, acc_wo: 1.000, acc_wvi: 0.990, acc_wv: 0.311, acc_lx: 0.301, acc_x: 0.350\n","dev results ------------\n"," Epoch: 39, ave loss: 6.756791353225708, acc_sc: 0.933, acc_sa: 0.800, acc_wn: 0.867,         acc_wc: 0.600, acc_wo: 0.867, acc_wvi: 0.400, acc_wv: 0.133, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 14\n","\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"6nydLzkYAbKD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634309898728,"user_tz":-540,"elapsed":15813,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"31c67ed0-3bf2-4122-bd4c-7f024efaf263"},"source":["# dev\n","!python3 predict_ale_kobert.py --bert_type_abb ko \\\n","    --model_file ../result_files/CoreNLP/KoBERT/model_best.pt \\\n","    --bert_model_file ../result_files/CoreNLP/KoBERT/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/CoreNLP/KoBERT \\\n","    --data_path ./data_and_model/for_test_144/CoreNLP \\\n","    --split dev\n","\n","!python3 evaluate_ws.py"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\u001b[0m./data_and_model/for_test_144/CoreNLP/dev.db\n","100% 15/15 [00:00<00:00, 468.01it/s]\n","{\n","  \"ex_accuracy\": 0.4,\n","  \"lf_accuracy\": 0.13333333333333333\n","}\n"]}]},{"cell_type":"code","metadata":{"id":"uPl0nAQtAbQ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634309958051,"user_tz":-540,"elapsed":15817,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"e3b2a952-d8f1-4af4-bff3-ef163786e325"},"source":["# test\n","!python3 predict_ale_kobert.py --bert_type_abb ko \\\n","    --model_file ../result_files/CoreNLP/KoBERT/model_best.pt \\\n","    --bert_model_file ../result_files/CoreNLP/KoBERT/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/CoreNLP/KoBERT \\\n","    --data_path ./data_and_model/for_test_144/CoreNLP \\\n","    --split test\n","\n","!python3 evaluate_ws.py"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\u001b[0m./data_and_model/for_test_144/CoreNLP/test.db\n","100% 26/26 [00:00<00:00, 307.17it/s]\n","{\n","  \"ex_accuracy\": 0.3076923076923077,\n","  \"lf_accuracy\": 0.11538461538461539\n","}\n"]}]},{"cell_type":"markdown","metadata":{"id":"6pw8_SaoAMT-"},"source":["####okt, mcs"]},{"cell_type":"code","metadata":{"id":"Cuc5zoEp_Lmf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634310360370,"user_tz":-540,"elapsed":307754,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"df1cef5d-e727-4aa2-f1e5-93e88fc84175"},"source":["!python3 train_ale.py --do_train --tepoch 40 --seed 1 --bS 4 \\\n","    --accumulate_gradients 2 --bert_type_abb mcS --fine_tune \\\n","    --lr 0.0001 --lr_bert 0.00001 --max_seq_leng 222"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Batch_size = 8\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: True\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Load pre-trained parameters.\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.0001\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","train results ------------\n"," Epoch: 0, ave loss: 8.363639090825053, acc_sc: 0.204, acc_sa: 0.233, acc_wn: 0.427,         acc_wc: 0.068, acc_wo: 0.398, acc_wvi: 0.029, acc_wv: 0.049, acc_lx: 0.000, acc_x: 0.000\n","dev results ------------\n"," Epoch: 0, ave loss: 6.984537506103516, acc_sc: 0.267, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.133, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 1, ave loss: 7.816243551309826, acc_sc: 0.165, acc_sa: 0.689, acc_wn: 0.913,         acc_wc: 0.252, acc_wo: 0.913, acc_wvi: 0.214, acc_wv: 0.243, acc_lx: 0.019, acc_x: 0.029\n","dev results ------------\n"," Epoch: 1, ave loss: 6.499227650960287, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.067, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 2, ave loss: 7.216316871272707, acc_sc: 0.252, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.204, acc_wo: 0.913, acc_wvi: 0.155, acc_wv: 0.262, acc_lx: 0.010, acc_x: 0.019\n","dev results ------------\n"," Epoch: 2, ave loss: 5.977590179443359, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.133, acc_wo: 0.733, acc_wvi: 0.067, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 3, ave loss: 6.438253458263804, acc_sc: 0.359, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.233, acc_wo: 0.913, acc_wvi: 0.155, acc_wv: 0.243, acc_lx: 0.019, acc_x: 0.019\n","dev results ------------\n"," Epoch: 3, ave loss: 5.381350962320964, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.200, acc_wo: 0.733, acc_wvi: 0.200, acc_wv: 0.200, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 4, ave loss: 5.726752346001782, acc_sc: 0.466, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.175, acc_wo: 0.913, acc_wvi: 0.126, acc_wv: 0.204, acc_lx: 0.019, acc_x: 0.029\n","dev results ------------\n"," Epoch: 4, ave loss: 4.879058074951172, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 5, ave loss: 5.054345010553749, acc_sc: 0.437, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.243, acc_wo: 0.913, acc_wvi: 0.223, acc_wv: 0.262, acc_lx: 0.029, acc_x: 0.049\n","dev results ------------\n"," Epoch: 5, ave loss: 4.266993713378906, acc_sc: 0.600, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 6, ave loss: 4.350526133787285, acc_sc: 0.544, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.243, acc_wo: 0.913, acc_wvi: 0.301, acc_wv: 0.282, acc_lx: 0.029, acc_x: 0.058\n","dev results ------------\n"," Epoch: 6, ave loss: 3.8213284810384116, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 7, ave loss: 3.6373421567157633, acc_sc: 0.612, acc_sa: 0.699, acc_wn: 0.913,         acc_wc: 0.282, acc_wo: 0.913, acc_wvi: 0.320, acc_wv: 0.272, acc_lx: 0.049, acc_x: 0.068\n","dev results ------------\n"," Epoch: 7, ave loss: 3.389385795593262, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 8, ave loss: 3.006751375290954, acc_sc: 0.670, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.252, acc_wo: 0.913, acc_wvi: 0.398, acc_wv: 0.340, acc_lx: 0.029, acc_x: 0.068\n","dev results ------------\n"," Epoch: 8, ave loss: 3.0288764953613283, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.333, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 9, ave loss: 2.501265197124296, acc_sc: 0.709, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.272, acc_wo: 0.913, acc_wvi: 0.437, acc_wv: 0.369, acc_lx: 0.039, acc_x: 0.058\n","dev results ------------\n"," Epoch: 9, ave loss: 2.7398960113525392, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.333, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","train results ------------\n"," Epoch: 10, ave loss: 2.0460040360978504, acc_sc: 0.728, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.282, acc_wo: 0.913, acc_wvi: 0.544, acc_wv: 0.456, acc_lx: 0.087, acc_x: 0.126\n","dev results ------------\n"," Epoch: 10, ave loss: 2.9629165013631185, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.067, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.06666666666666667 at epoch: 10\n","train results ------------\n"," Epoch: 11, ave loss: 1.7041443273859116, acc_sc: 0.777, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.359, acc_wo: 0.913, acc_wvi: 0.612, acc_wv: 0.524, acc_lx: 0.107, acc_x: 0.136\n","dev results ------------\n"," Epoch: 11, ave loss: 2.643959808349609, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.067, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.06666666666666667 at epoch: 10\n","train results ------------\n"," Epoch: 12, ave loss: 1.4385639579550733, acc_sc: 0.816, acc_sa: 0.689, acc_wn: 0.913,         acc_wc: 0.359, acc_wo: 0.913, acc_wvi: 0.767, acc_wv: 0.699, acc_lx: 0.126, acc_x: 0.175\n","dev results ------------\n"," Epoch: 12, ave loss: 2.388902695973714, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.333, acc_wv: 0.267, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 12\n","train results ------------\n"," Epoch: 13, ave loss: 1.2971661391767484, acc_sc: 0.854, acc_sa: 0.689, acc_wn: 0.922,         acc_wc: 0.408, acc_wo: 0.922, acc_wvi: 0.874, acc_wv: 0.786, acc_lx: 0.194, acc_x: 0.252\n","dev results ------------\n"," Epoch: 13, ave loss: 2.42114626566569, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 12\n","train results ------------\n"," Epoch: 14, ave loss: 1.1918347090193369, acc_sc: 0.864, acc_sa: 0.689, acc_wn: 0.913,         acc_wc: 0.456, acc_wo: 0.913, acc_wvi: 0.854, acc_wv: 0.757, acc_lx: 0.194, acc_x: 0.282\n","dev results ------------\n"," Epoch: 14, ave loss: 2.3146461804707843, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 14\n","train results ------------\n"," Epoch: 15, ave loss: 1.1262496813987066, acc_sc: 0.922, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.534, acc_wo: 0.913, acc_wvi: 0.864, acc_wv: 0.777, acc_lx: 0.262, acc_x: 0.330\n","dev results ------------\n"," Epoch: 15, ave loss: 2.283399788538615, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 14\n","train results ------------\n"," Epoch: 16, ave loss: 1.0468547228470588, acc_sc: 0.883, acc_sa: 0.699, acc_wn: 0.913,         acc_wc: 0.592, acc_wo: 0.913, acc_wvi: 0.883, acc_wv: 0.786, acc_lx: 0.320, acc_x: 0.369\n","dev results ------------\n"," Epoch: 16, ave loss: 1.9737671693166097, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 14\n","train results ------------\n"," Epoch: 17, ave loss: 0.9069270462665743, acc_sc: 0.932, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.621, acc_wo: 0.913, acc_wvi: 0.893, acc_wv: 0.796, acc_lx: 0.320, acc_x: 0.408\n","dev results ------------\n"," Epoch: 17, ave loss: 2.1795599937438963, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 14\n","train results ------------\n"," Epoch: 18, ave loss: 0.8223271705571887, acc_sc: 0.883, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.660, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.379, acc_x: 0.437\n","dev results ------------\n"," Epoch: 18, ave loss: 2.152883434295654, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 19, ave loss: 0.708131631601204, acc_sc: 0.903, acc_sa: 0.689, acc_wn: 0.922,         acc_wc: 0.670, acc_wo: 0.922, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.417, acc_x: 0.456\n","dev results ------------\n"," Epoch: 19, ave loss: 2.2792142073313397, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 20, ave loss: 0.6845269978625103, acc_sc: 0.893, acc_sa: 0.680, acc_wn: 0.922,         acc_wc: 0.709, acc_wo: 0.922, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.427, acc_x: 0.505\n","dev results ------------\n"," Epoch: 20, ave loss: 2.3834249496459963, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 21, ave loss: 0.6798850240059269, acc_sc: 0.913, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.699, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.398, acc_x: 0.485\n","dev results ------------\n"," Epoch: 21, ave loss: 2.229587745666504, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 22, ave loss: 0.6248478333926896, acc_sc: 0.932, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.718, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.447, acc_x: 0.524\n","dev results ------------\n"," Epoch: 22, ave loss: 2.4146694978078207, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.267, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 23, ave loss: 0.6567880181432928, acc_sc: 0.942, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.699, acc_wo: 0.913, acc_wvi: 0.903, acc_wv: 0.806, acc_lx: 0.417, acc_x: 0.505\n","dev results ------------\n"," Epoch: 23, ave loss: 2.18523858388265, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 24, ave loss: 0.5805843883347743, acc_sc: 0.951, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.767, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.466, acc_x: 0.553\n","dev results ------------\n"," Epoch: 24, ave loss: 2.0817771196365356, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 25, ave loss: 0.5798774679887642, acc_sc: 0.942, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.709, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.398, acc_x: 0.505\n","dev results ------------\n"," Epoch: 25, ave loss: 2.029379192988078, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 26, ave loss: 0.5209667555336813, acc_sc: 0.942, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.738, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.417, acc_x: 0.485\n","dev results ------------\n"," Epoch: 26, ave loss: 2.071278278032939, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.733, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 27, ave loss: 0.48577405295325715, acc_sc: 0.951, acc_sa: 0.699, acc_wn: 0.913,         acc_wc: 0.748, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.485, acc_x: 0.524\n","dev results ------------\n"," Epoch: 27, ave loss: 2.1769976218541465, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.267, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 28, ave loss: 0.4755969562576812, acc_sc: 0.951, acc_sa: 0.709, acc_wn: 0.913,         acc_wc: 0.757, acc_wo: 0.913, acc_wvi: 0.903, acc_wv: 0.806, acc_lx: 0.476, acc_x: 0.534\n","dev results ------------\n"," Epoch: 28, ave loss: 2.112095864613851, acc_sc: 0.667, acc_sa: 0.533, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 29, ave loss: 0.4631500452467539, acc_sc: 0.951, acc_sa: 0.738, acc_wn: 0.913,         acc_wc: 0.777, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.534, acc_x: 0.563\n","dev results ------------\n"," Epoch: 29, ave loss: 1.7823764403661093, acc_sc: 0.733, acc_sa: 0.533, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 30, ave loss: 0.39824590926031467, acc_sc: 0.951, acc_sa: 0.816, acc_wn: 0.922,         acc_wc: 0.748, acc_wo: 0.922, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.573, acc_x: 0.583\n","dev results ------------\n"," Epoch: 30, ave loss: 2.250640058517456, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 31, ave loss: 0.3471203157045309, acc_sc: 0.961, acc_sa: 0.806, acc_wn: 0.922,         acc_wc: 0.786, acc_wo: 0.922, acc_wvi: 0.922, acc_wv: 0.835, acc_lx: 0.592, acc_x: 0.583\n","dev results ------------\n"," Epoch: 31, ave loss: 1.9838704347610474, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.267\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 32, ave loss: 0.3615300273432315, acc_sc: 0.942, acc_sa: 0.796, acc_wn: 0.913,         acc_wc: 0.806, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.563, acc_x: 0.573\n","dev results ------------\n"," Epoch: 32, ave loss: 1.911374839146932, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.267, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 33, ave loss: 0.34863308621841727, acc_sc: 0.942, acc_sa: 0.825, acc_wn: 0.913,         acc_wc: 0.777, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.583, acc_x: 0.592\n","dev results ------------\n"," Epoch: 33, ave loss: 2.332317042350769, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 34, ave loss: 0.34644307210607433, acc_sc: 0.951, acc_sa: 0.786, acc_wn: 0.913,         acc_wc: 0.777, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.534, acc_x: 0.544\n","dev results ------------\n"," Epoch: 34, ave loss: 2.3529164791107178, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 35, ave loss: 0.2965427119176365, acc_sc: 0.951, acc_sa: 0.854, acc_wn: 0.913,         acc_wc: 0.806, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.621, acc_x: 0.612\n","dev results ------------\n"," Epoch: 35, ave loss: 2.250167179107666, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.333\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 36, ave loss: 0.29536173268429283, acc_sc: 0.961, acc_sa: 0.825, acc_wn: 0.942,         acc_wc: 0.806, acc_wo: 0.932, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.573, acc_x: 0.573\n","dev results ------------\n"," Epoch: 36, ave loss: 2.063463830947876, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.667, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.333, acc_x: 0.333\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 37, ave loss: 0.27806095533000613, acc_sc: 0.961, acc_sa: 0.835, acc_wn: 0.942,         acc_wc: 0.835, acc_wo: 0.932, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.631, acc_x: 0.631\n","dev results ------------\n"," Epoch: 37, ave loss: 2.1742071866989137, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.600, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 38, ave loss: 0.24789572225033657, acc_sc: 0.961, acc_sa: 0.864, acc_wn: 0.961,         acc_wc: 0.816, acc_wo: 0.961, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.621, acc_x: 0.621\n","dev results ------------\n"," Epoch: 38, ave loss: 1.9220940907796225, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n","train results ------------\n"," Epoch: 39, ave loss: 0.24935387986377605, acc_sc: 0.961, acc_sa: 0.864, acc_wn: 0.951,         acc_wc: 0.874, acc_wo: 0.942, acc_wvi: 0.922, acc_wv: 0.816, acc_lx: 0.670, acc_x: 0.670\n","dev results ------------\n"," Epoch: 39, ave loss: 2.4025753577550253, acc_sc: 0.667, acc_sa: 0.467, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.3333333333333333 at epoch: 18\n"]}]},{"cell_type":"code","metadata":{"id":"xQozZaWiAdU1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634310369309,"user_tz":-540,"elapsed":8943,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"e0eac463-4427-41ed-943e-de6b769c7a7c"},"source":["# dev\n","!python3 predict.py --bert_type_abb mcS \\\n","    --model_file ../result_files/okt/mcS/model_best.pt \\\n","    --bert_model_file ../result_files/okt/mcS/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/okt/mcS \\\n","    --data_path ./data_and_model/for_test_144/okt \\\n","    --split dev\n","\n","!python3 evaluate_ws.py"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","./data_and_model/for_test_144/okt/dev.db\n","100% 15/15 [00:00<00:00, 439.15it/s]\n","{\n","  \"ex_accuracy\": 0.6,\n","  \"lf_accuracy\": 0.3333333333333333\n","}\n"]}]},{"cell_type":"code","metadata":{"id":"KHfwFGkTAex6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634310518065,"user_tz":-540,"elapsed":8225,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"f68bcf5e-12ca-499a-c4eb-668c4b0e747e"},"source":["# test\n","!python3 predict.py --bert_type_abb mcS \\\n","    --model_file ../result_files/okt/mcS/model_best.pt \\\n","    --bert_model_file ../result_files/okt/mcS/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/okt/mcS \\\n","    --data_path ./data_and_model/for_test_144/okt \\\n","    --split test\n","\n","!python3 evaluate_ws.py"],"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: multi_cased_L-12_H-768_A-12\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 119547\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","./data_and_model/for_test_144/okt/test.db\n","100% 26/26 [00:00<00:00, 307.37it/s]\n","{\n","  \"ex_accuracy\": 0.5769230769230769,\n","  \"lf_accuracy\": 0.38461538461538464\n","}\n"]}]},{"cell_type":"markdown","metadata":{"id":"f8OOnwJUAP-Q"},"source":["####okt, KoBERT"]},{"cell_type":"code","metadata":{"id":"OGheYBQX_DQS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634310873253,"user_tz":-540,"elapsed":263312,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"3ead99fa-8397-4c9f-9081-f0e579ad476b"},"source":["#okt, KoBERT\n","!python3 train_ale_kobert.py --do_train --tepoch 40 --seed 1 --bS 4 \\\n","    --accumulate_gradients 2 --bert_type_abb ko --fine_tune \\\n","    --lr 0.0005 --lr_bert 0.00005 --max_seq_leng 222"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Batch_size = 8\n","BERT parameters:\n","learning rate: 5e-05\n","Fine-tune BERT: True\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.0005\n","<generator object Module.parameters at 0x7f85155cfbd0>\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 0, ave loss: 7.778228704211782, acc_sc: 0.194, acc_sa: 0.495, acc_wn: 0.903,         acc_wc: 0.165, acc_wo: 0.845, acc_wvi: 0.126, acc_wv: 0.214, acc_lx: 0.019, acc_x: 0.019\n","dev results ------------\n"," Epoch: 0, ave loss: 5.847216415405273, acc_sc: 0.200, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.000, acc_wo: 0.733, acc_wvi: 0.067, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 1, ave loss: 5.94415651710288, acc_sc: 0.204, acc_sa: 0.699, acc_wn: 0.913,         acc_wc: 0.184, acc_wo: 0.913, acc_wvi: 0.126, acc_wv: 0.194, acc_lx: 0.010, acc_x: 0.019\n","dev results ------------\n"," Epoch: 1, ave loss: 5.101368077596029, acc_sc: 0.200, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.000, acc_wo: 0.733, acc_wvi: 0.067, acc_wv: 0.067, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 2, ave loss: 5.075603846207406, acc_sc: 0.291, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.194, acc_wo: 0.913, acc_wvi: 0.175, acc_wv: 0.155, acc_lx: 0.010, acc_x: 0.010\n","dev results ------------\n"," Epoch: 2, ave loss: 4.590411376953125, acc_sc: 0.267, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.067, acc_wo: 0.733, acc_wvi: 0.000, acc_wv: 0.000, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 3, ave loss: 3.65189775448401, acc_sc: 0.291, acc_sa: 0.680, acc_wn: 0.922,         acc_wc: 0.184, acc_wo: 0.922, acc_wvi: 0.301, acc_wv: 0.291, acc_lx: 0.019, acc_x: 0.019\n","dev results ------------\n"," Epoch: 3, ave loss: 3.315652910868327, acc_sc: 0.400, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.000, acc_wo: 0.733, acc_wvi: 0.133, acc_wv: 0.133, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 4, ave loss: 2.3937268257141113, acc_sc: 0.301, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.204, acc_wo: 0.913, acc_wvi: 0.437, acc_wv: 0.379, acc_lx: 0.039, acc_x: 0.058\n","dev results ------------\n"," Epoch: 4, ave loss: 3.0488170623779296, acc_sc: 0.533, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.200, acc_wo: 0.733, acc_wvi: 0.267, acc_wv: 0.200, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 5, ave loss: 1.5615174608323181, acc_sc: 0.505, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.291, acc_wo: 0.913, acc_wvi: 0.806, acc_wv: 0.728, acc_lx: 0.068, acc_x: 0.078\n","dev results ------------\n"," Epoch: 5, ave loss: 2.8786657015482584, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.133, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 6, ave loss: 1.0733093914476413, acc_sc: 0.650, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.291, acc_wo: 0.913, acc_wvi: 0.864, acc_wv: 0.767, acc_lx: 0.117, acc_x: 0.136\n","dev results ------------\n"," Epoch: 6, ave loss: 2.811913426717122, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.133, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 7, ave loss: 0.8756629147575897, acc_sc: 0.718, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.350, acc_wo: 0.913, acc_wvi: 0.893, acc_wv: 0.796, acc_lx: 0.136, acc_x: 0.155\n","dev results ------------\n"," Epoch: 7, ave loss: 2.8767509778340656, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.000, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 8, ave loss: 0.7140950832552123, acc_sc: 0.767, acc_sa: 0.670, acc_wn: 0.913,         acc_wc: 0.437, acc_wo: 0.913, acc_wvi: 0.903, acc_wv: 0.806, acc_lx: 0.252, acc_x: 0.272\n","dev results ------------\n"," Epoch: 8, ave loss: 3.2381153106689453, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.267, acc_wo: 0.733, acc_wvi: 0.333, acc_wv: 0.267, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 9, ave loss: 0.6907665451753486, acc_sc: 0.806, acc_sa: 0.680, acc_wn: 0.922,         acc_wc: 0.534, acc_wo: 0.922, acc_wvi: 0.893, acc_wv: 0.796, acc_lx: 0.272, acc_x: 0.330\n","dev results ------------\n"," Epoch: 9, ave loss: 2.864175780614217, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.333, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.0 at epoch: 0\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 10, ave loss: 0.6167740428331986, acc_sc: 0.825, acc_sa: 0.680, acc_wn: 0.913,         acc_wc: 0.612, acc_wo: 0.913, acc_wvi: 0.903, acc_wv: 0.806, acc_lx: 0.369, acc_x: 0.408\n","dev results ------------\n"," Epoch: 10, ave loss: 2.558315070470174, acc_sc: 0.733, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.333, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.06666666666666667 at epoch: 10\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 11, ave loss: 0.5204611420631409, acc_sc: 0.903, acc_sa: 0.738, acc_wn: 0.913,         acc_wc: 0.670, acc_wo: 0.913, acc_wvi: 0.903, acc_wv: 0.806, acc_lx: 0.427, acc_x: 0.466\n","dev results ------------\n"," Epoch: 11, ave loss: 2.928445339202881, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.333, acc_wv: 0.267, acc_lx: 0.000, acc_x: 0.000\n"," Best Dev lx acc: 0.06666666666666667 at epoch: 10\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 12, ave loss: 0.46407960456551856, acc_sc: 0.903, acc_sa: 0.748, acc_wn: 0.913,         acc_wc: 0.641, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.388, acc_x: 0.427\n","dev results ------------\n"," Epoch: 12, ave loss: 3.2012270291646323, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.067, acc_x: 0.000\n"," Best Dev lx acc: 0.06666666666666667 at epoch: 10\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 13, ave loss: 0.36383898454962427, acc_sc: 0.932, acc_sa: 0.816, acc_wn: 0.913,         acc_wc: 0.670, acc_wo: 0.913, acc_wvi: 0.913, acc_wv: 0.816, acc_lx: 0.466, acc_x: 0.476\n","dev results ------------\n"," Epoch: 13, ave loss: 3.0242826461791994, acc_sc: 0.667, acc_sa: 0.600, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 14, ave loss: 0.300388595722254, acc_sc: 0.922, acc_sa: 0.845, acc_wn: 0.942,         acc_wc: 0.757, acc_wo: 0.942, acc_wvi: 0.913, acc_wv: 0.825, acc_lx: 0.553, acc_x: 0.583\n","dev results ------------\n"," Epoch: 14, ave loss: 3.019352674484253, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 15, ave loss: 0.2651744674421051, acc_sc: 0.932, acc_sa: 0.883, acc_wn: 0.971,         acc_wc: 0.854, acc_wo: 0.961, acc_wvi: 0.922, acc_wv: 0.835, acc_lx: 0.660, acc_x: 0.660\n","dev results ------------\n"," Epoch: 15, ave loss: 2.9813485781351727, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 16, ave loss: 0.2150198387578853, acc_sc: 0.961, acc_sa: 0.893, acc_wn: 0.942,         acc_wc: 0.777, acc_wo: 0.932, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.592, acc_x: 0.602\n","dev results ------------\n"," Epoch: 16, ave loss: 2.926709794998169, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.600,         acc_wc: 0.400, acc_wo: 0.600, acc_wvi: 0.400, acc_wv: 0.333, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 17, ave loss: 0.18180340962502564, acc_sc: 0.951, acc_sa: 0.893, acc_wn: 0.951,         acc_wc: 0.845, acc_wo: 0.951, acc_wvi: 0.922, acc_wv: 0.825, acc_lx: 0.660, acc_x: 0.660\n","dev results ------------\n"," Epoch: 17, ave loss: 3.0450151602427167, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 18, ave loss: 0.16504085975364574, acc_sc: 0.942, acc_sa: 0.893, acc_wn: 0.961,         acc_wc: 0.835, acc_wo: 0.961, acc_wvi: 0.932, acc_wv: 0.835, acc_lx: 0.670, acc_x: 0.660\n","dev results ------------\n"," Epoch: 18, ave loss: 3.2329305013020835, acc_sc: 0.667, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 19, ave loss: 0.16899081435307717, acc_sc: 0.951, acc_sa: 0.932, acc_wn: 0.951,         acc_wc: 0.874, acc_wo: 0.951, acc_wvi: 0.913, acc_wv: 0.806, acc_lx: 0.709, acc_x: 0.728\n","dev results ------------\n"," Epoch: 19, ave loss: 3.4713243007659913, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 20, ave loss: 0.18081566561194298, acc_sc: 0.951, acc_sa: 0.883, acc_wn: 0.951,         acc_wc: 0.903, acc_wo: 0.951, acc_wvi: 0.932, acc_wv: 0.816, acc_lx: 0.709, acc_x: 0.718\n","dev results ------------\n"," Epoch: 20, ave loss: 3.5353880405426024, acc_sc: 0.667, acc_sa: 0.467, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.067, acc_x: 0.067\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 21, ave loss: 0.18086555585699174, acc_sc: 0.942, acc_sa: 0.845, acc_wn: 0.961,         acc_wc: 0.883, acc_wo: 0.961, acc_wvi: 0.932, acc_wv: 0.825, acc_lx: 0.641, acc_x: 0.670\n","dev results ------------\n"," Epoch: 21, ave loss: 3.1575754563013714, acc_sc: 0.667, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 22, ave loss: 0.16109595758822357, acc_sc: 0.942, acc_sa: 0.893, acc_wn: 0.961,         acc_wc: 0.864, acc_wo: 0.961, acc_wvi: 0.932, acc_wv: 0.816, acc_lx: 0.670, acc_x: 0.709\n","dev results ------------\n"," Epoch: 22, ave loss: 2.9991331259409586, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.13333333333333333 at epoch: 13\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 23, ave loss: 0.12981862943727993, acc_sc: 0.961, acc_sa: 0.913, acc_wn: 0.961,         acc_wc: 0.903, acc_wo: 0.961, acc_wvi: 0.932, acc_wv: 0.816, acc_lx: 0.728, acc_x: 0.748\n","dev results ------------\n"," Epoch: 23, ave loss: 3.4181602239608764, acc_sc: 0.733, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 24, ave loss: 0.1404722056631903, acc_sc: 0.951, acc_sa: 0.922, acc_wn: 0.961,         acc_wc: 0.864, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.835, acc_lx: 0.709, acc_x: 0.709\n","dev results ------------\n"," Epoch: 24, ave loss: 3.250291021664937, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 25, ave loss: 0.09438502904280875, acc_sc: 0.961, acc_sa: 0.942, acc_wn: 0.961,         acc_wc: 0.922, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.825, acc_lx: 0.767, acc_x: 0.767\n","dev results ------------\n"," Epoch: 25, ave loss: 3.3747944831848145, acc_sc: 0.600, acc_sa: 0.667, acc_wn: 0.733,         acc_wc: 0.400, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.067\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 26, ave loss: 0.09155342879804593, acc_sc: 0.961, acc_sa: 0.942, acc_wn: 0.961,         acc_wc: 0.942, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.816, acc_lx: 0.786, acc_x: 0.806\n","dev results ------------\n"," Epoch: 26, ave loss: 3.3374734044075014, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 27, ave loss: 0.07813834449619923, acc_sc: 0.961, acc_sa: 0.951, acc_wn: 0.961,         acc_wc: 0.874, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.835, acc_lx: 0.748, acc_x: 0.728\n","dev results ------------\n"," Epoch: 27, ave loss: 3.3673893411954245, acc_sc: 0.600, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 28, ave loss: 0.06478272671404395, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.893, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.845, acc_lx: 0.786, acc_x: 0.786\n","dev results ------------\n"," Epoch: 28, ave loss: 3.401114900906881, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 29, ave loss: 0.05431227288344531, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.942, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.845, acc_lx: 0.825, acc_x: 0.816\n","dev results ------------\n"," Epoch: 29, ave loss: 3.4305845499038696, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 30, ave loss: 0.06047511230973364, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.942, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.825, acc_lx: 0.806, acc_x: 0.806\n","dev results ------------\n"," Epoch: 30, ave loss: 3.45263135433197, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 31, ave loss: 0.10135608593237053, acc_sc: 0.913, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.942, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.825, acc_lx: 0.767, acc_x: 0.767\n","dev results ------------\n"," Epoch: 31, ave loss: 3.20033100048701, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 32, ave loss: 0.0638187231080046, acc_sc: 0.942, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.825, acc_lx: 0.796, acc_x: 0.806\n","dev results ------------\n"," Epoch: 32, ave loss: 3.3950894435246783, acc_sc: 0.667, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.067, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 33, ave loss: 0.05777343773075099, acc_sc: 0.951, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.942, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.835, acc_lx: 0.806, acc_x: 0.816\n","dev results ------------\n"," Epoch: 33, ave loss: 3.5014347632726035, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 34, ave loss: 0.04473871001702489, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.835, acc_lx: 0.825, acc_x: 0.816\n","dev results ------------\n"," Epoch: 34, ave loss: 3.443260828653971, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 35, ave loss: 0.03941177840805748, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.942, acc_wv: 0.825, acc_lx: 0.816, acc_x: 0.806\n","dev results ------------\n"," Epoch: 35, ave loss: 3.5384527405103046, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 36, ave loss: 0.04105846920204394, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.835, acc_lx: 0.825, acc_x: 0.825\n","dev results ------------\n"," Epoch: 36, ave loss: 3.594413693745931, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 37, ave loss: 0.03752205661018786, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.825, acc_lx: 0.816, acc_x: 0.816\n","dev results ------------\n"," Epoch: 37, ave loss: 3.600958069165548, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 38, ave loss: 0.03037081537677825, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.951, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.825, acc_lx: 0.816, acc_x: 0.816\n","dev results ------------\n"," Epoch: 38, ave loss: 3.6470621744791667, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.533, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.200, acc_x: 0.200\n"," Best Dev lx acc: 0.2 at epoch: 23\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","train results ------------\n"," Epoch: 39, ave loss: 0.030928051126307074, acc_sc: 0.961, acc_sa: 0.961, acc_wn: 0.961,         acc_wc: 0.961, acc_wo: 0.961, acc_wvi: 0.951, acc_wv: 0.825, acc_lx: 0.825, acc_x: 0.825\n","dev results ------------\n"," Epoch: 39, ave loss: 3.6482649743556976, acc_sc: 0.733, acc_sa: 0.733, acc_wn: 0.733,         acc_wc: 0.467, acc_wo: 0.733, acc_wvi: 0.467, acc_wv: 0.400, acc_lx: 0.133, acc_x: 0.133\n"," Best Dev lx acc: 0.2 at epoch: 23\n","\u001b[0m"]}]},{"cell_type":"code","metadata":{"id":"MZk6jFQeAfs-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634310929840,"user_tz":-540,"elapsed":15826,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"9d964f95-0dcf-4a31-ad17-71bf7081f46e"},"source":["# dev\n","!python3 predict_ale_kobert.py --bert_type_abb ko \\\n","    --model_file ../result_files/okt/KoBERT/model_best.pt \\\n","    --bert_model_file ../result_files/okt/KoBERT/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/okt/KoBERT \\\n","    --data_path ./data_and_model/for_test_144/okt \\\n","    --split dev\n","\n","!python3 evaluate_ws.py"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\u001b[0m./data_and_model/for_test_144/okt/dev.db\n","100% 15/15 [00:00<00:00, 445.65it/s]\n","{\n","  \"ex_accuracy\": 0.4666666666666667,\n","  \"lf_accuracy\": 0.2\n","}\n"]}]},{"cell_type":"code","metadata":{"id":"ow8WMcVeAfxx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634311031932,"user_tz":-540,"elapsed":16020,"user":{"displayName":"안이은","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjwfP1nargAWSkeqTSFHrYPrcl29hrjqe61sX5y=s64","userId":"12846418655285663013"}},"outputId":"c6556d2c-2a77-4667-d867-1d9cd67e1aca"},"source":["# test\n","!python3 predict_ale_kobert.py --bert_type_abb ko \\\n","    --model_file ../result_files/okt/KoBERT/model_best.pt \\\n","    --bert_model_file ../result_files/okt/KoBERT/model_bert_best.pt \\\n","    --bert_path ./data_and_model \\\n","    --result_path ../result_files/okt/KoBERT \\\n","    --data_path ./data_and_model/for_test_144/okt \\\n","    --split test\n","\n","!python3 evaluate_ws.py"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["BERT-type: kobert\n","Batch_size = 32\n","BERT parameters:\n","learning rate: 1e-05\n","Fine-tune BERT: False\n","vocab size: 8002\n","hidden_size: 768\n","num_hidden_layer: 12\n","num_attention_heads: 12\n","hidden_act: gelu\n","intermediate_size: 3072\n","hidden_dropout_prob: 0.1\n","attention_probs_dropout_prob: 0.1\n","max_position_embeddings: 512\n","type_vocab_size: 2\n","initializer_range: 0.02\n","using cached model\n","using cached model\n","using cached model\n","Seq-to-SQL: the number of final BERT layers to be used: 2\n","Seq-to-SQL: the size of hidden dimension = 100\n","Seq-to-SQL: LSTM encoding layer size = 2\n","Seq-to-SQL: dropout rate = 0.3\n","Seq-to-SQL: learning rate = 0.001\n","The current process just got forked. Disabling parallelism to avoid deadlocks...\n","To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n","\u001b[0m./data_and_model/for_test_144/okt/test.db\n","100% 26/26 [00:00<00:00, 308.79it/s]\n","{\n","  \"ex_accuracy\": 0.5,\n","  \"lf_accuracy\": 0.38461538461538464\n","}\n"]}]}]}